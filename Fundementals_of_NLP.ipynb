{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fundementals of NLP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O_K3dHZqIo2"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yqo55cMYqXOk",
        "outputId": "a29d37f3-c814-4d09-c0d8-8481a00ebfc0"
      },
      "source": [
        "!wget \"https://raw.githubusercontent.com/akshaycholapurath/DeepNNwithTensorflow/master/helper_function.py\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-21 15:46:38--  https://raw.githubusercontent.com/akshaycholapurath/DeepNNwithTensorflow/master/helper_function.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10475 (10K) [text/plain]\n",
            "Saving to: ‘helper_function.py’\n",
            "\n",
            "\rhelper_function.py    0%[                    ]       0  --.-KB/s               \rhelper_function.py  100%[===================>]  10.23K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-05-21 15:46:38 (104 MB/s) - ‘helper_function.py’ saved [10475/10475]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqVf3VAfq0wF"
      },
      "source": [
        "Import the helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6N66a5I1qXYO"
      },
      "source": [
        "from helper_function import unzip_data,create_tensorboard_callback,plot_loss_curves,compare_historys"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWMDTFeHqXfv",
        "outputId": "55ef12d6-bc38-4e90-f280-3430411c6544"
      },
      "source": [
        "#Get the text dataset - Tweets with labels disaster or not disaster\n",
        "!wget \"https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\"\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-21 15:46:39--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.253.63.128, 142.250.31.128, 172.217.164.144, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.253.63.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2021-05-21 15:46:39 (69.5 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayYVjMf-qXqs"
      },
      "source": [
        "unzip_data('/content/nlp_getting_started.zip')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "O-F7PSpprWWK",
        "outputId": "24b3a4ac-e594-4eb7-922a-7bb9feda0a21"
      },
      "source": [
        "train_df = pd.read_csv('/content/train.csv')\n",
        "test_df = pd.read_csv('/content/test.csv')\n",
        "\n",
        "test_df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "JKtSdnx9uhbh",
        "outputId": "6eda82cc-c521-46b4-d46b-b0a227736e35"
      },
      "source": [
        "\n",
        "train_df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ma8bNt-TunzC"
      },
      "source": [
        "train_df = train_df.sample(frac=1,random_state=42)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJozr_uovM_9",
        "outputId": "36d98110-b597-4f65-a0d5-fe1baf11dae3"
      },
      "source": [
        "train_df['target'].value_counts()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "btPKV1AzrWew",
        "outputId": "629de5ed-a500-4030-9eed-9b1b73f3b4f9"
      },
      "source": [
        "train_df.describe(include = 'all')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>7613.000000</td>\n",
              "      <td>7552</td>\n",
              "      <td>5080</td>\n",
              "      <td>7613</td>\n",
              "      <td>7613.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>NaN</td>\n",
              "      <td>221</td>\n",
              "      <td>3341</td>\n",
              "      <td>7503</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>NaN</td>\n",
              "      <td>fatalities</td>\n",
              "      <td>USA</td>\n",
              "      <td>11-Year-Old Boy Charged With Manslaughter of T...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>NaN</td>\n",
              "      <td>45</td>\n",
              "      <td>104</td>\n",
              "      <td>10</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5441.934848</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.42966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3137.116090</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.49506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2734.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5408.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8146.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>10873.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  id  ...      target\n",
              "count    7613.000000  ...  7613.00000\n",
              "unique           NaN  ...         NaN\n",
              "top              NaN  ...         NaN\n",
              "freq             NaN  ...         NaN\n",
              "mean     5441.934848  ...     0.42966\n",
              "std      3137.116090  ...     0.49506\n",
              "min         1.000000  ...     0.00000\n",
              "25%      2734.000000  ...     0.00000\n",
              "50%      5408.000000  ...     0.00000\n",
              "75%      8146.000000  ...     1.00000\n",
              "max     10873.000000  ...     1.00000\n",
              "\n",
              "[11 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odX7GE2RrWlI",
        "outputId": "7dc13817-7d5c-4af9-fb44-dc7c169e6be1"
      },
      "source": [
        "import random\n",
        "\n",
        "random_index = random.randint(0,len(train_df)-5)\n",
        "for row in train_df[['text','target']][random_index:random_index+5].itertuples():\n",
        "  _,text,target = row\n",
        "  print(f\"Target:{target}\",\"(real dissaster)\" if target >0 else \"(not real disaster)\")\n",
        "  print(f\"Text:\\n {text} \\n\")\n",
        "  print(\"---\\n\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target:1 (real dissaster)\n",
            "Text:\n",
            " Holy moly that was crushed. \n",
            "\n",
            "---\n",
            "\n",
            "Target:1 (real dissaster)\n",
            "Text:\n",
            " @gilmanrocks7 wow. Where is this? For the rest of the summer I usually have to worry about forest fires. Calgary is about 8 hours away. \n",
            "\n",
            "---\n",
            "\n",
            "Target:0 (not real disaster)\n",
            "Text:\n",
            " US wants future first responders to be more high-tech - http://t.co/1VI2RNbK2i \n",
            "\n",
            "---\n",
            "\n",
            "Target:0 (not real disaster)\n",
            "Text:\n",
            " Quality Metrics Penalties May Harm Patient Care PCPs Say: Primary care physicians generally hold positive vi... http://t.co/TdwprVB04y \n",
            "\n",
            "---\n",
            "\n",
            "Target:0 (not real disaster)\n",
            "Text:\n",
            " RT RoadID: Thanks to Alex for his story &amp; to all first responders for being there when we need you. Û_ http://t.co/HikDC1fM2F \n",
            "\n",
            "---\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04GEKp2ezsbx"
      },
      "source": [
        "X = train_df['text'].to_numpy()\n",
        "y = train_df['target'].to_numpy()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tD5y8i3LzyVX",
        "outputId": "c1bec270-b5f6-4c53-bc42-014e1d4c3112"
      },
      "source": [
        "y"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, ..., 0, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0k9EK8Os8Wd"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.1,random_state=42)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0N_X3WKMs8dL",
        "outputId": "b9d71182-ce2d-458f-c638-47f388c05f45"
      },
      "source": [
        "x_train[:10],y_train[:10]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object), array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sf5dScHH0_Qi",
        "outputId": "0f0f7354-2312-4276-8e5c-368133f14cc1"
      },
      "source": [
        "len(x_train),len(y_train),len(x_test),len(y_test)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87TM4hun11Q8"
      },
      "source": [
        "# Tokenize Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEtu9aLo0_Z9"
      },
      "source": [
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3MJEniY0_hq",
        "outputId": "709dedd7-58f0-4066-a78e-5a4e3618c664"
      },
      "source": [
        "round(sum([len(i.split()) for i in x_train])/len(x_train))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxxiZFEf9VsI"
      },
      "source": [
        "max_vocab_size=10000\n",
        "max_length = 15\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_size,\n",
        "                                    standardize='lower_and_strip_punctuation',\n",
        "                                    split='whitespace',ngrams=None,\n",
        "                                    output_mode = 'int',output_sequence_length=max_length,\n",
        "                                    pad_to_max_tokens=True)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8uUxjPV9WK-"
      },
      "source": [
        "#Fit text_vectorizer to training data\n",
        "text_vectorizer.adapt(x_train)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOETawz2-47W",
        "outputId": "6ed252b2-6e9a-438c-dbcb-95ebea09e526"
      },
      "source": [
        "x_train"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "       'Imagine getting flattened by Kurt Zouma',\n",
              "       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "       ...,\n",
              "       'Near them on the sand half sunk a shattered visage lies... http://t.co/0kCCG1BT06',\n",
              "       \"kesabaran membuahkan hasil indah pada saat tepat! life isn't about waiting for the storm to pass it's about learning to dance in the rain.\",\n",
              "       \"@ScottDPierce @billharris_tv @HarrisGle @Beezersun I'm forfeiting this years fantasy football pool out of fear I may win n get my ass kicked\"],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPjnQCz1_A4n",
        "outputId": "4b8c757a-033c-4e3b-d907-9c683769acdb"
      },
      "source": [
        "sample = 'This is a really good exercise'\n",
        "text_vectorizer([sample])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[ 19,   9,   3, 169, 136,   1,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nHWr8M0KcvL",
        "outputId": "ff24a48c-77f6-432f-a493-6d3cacb87030"
      },
      "source": [
        "#Get the unique words and their tokens\n",
        "words = text_vectorizer.get_vocabulary()\n",
        "words[:10]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VxepEuyKrqJ",
        "outputId": "d1852f6f-47da-47f3-a5e7-e05746d14178"
      },
      "source": [
        "words[-5:]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91S_XWFXLtpC"
      },
      "source": [
        "# Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPHdfxU4LueY"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "#converts each int token into a 128 dim vector randomly initialized\n",
        "\n",
        "embedding = layers.Embedding(input_dim = max_vocab_size,\n",
        "                             output_dim = 128,\n",
        "                             input_length=max_length)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOipda7g_-Pf"
      },
      "source": [
        "# Model_0 :Naive Bayes with TF-IDF encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8At7Z4nAfHT"
      },
      "source": [
        "Base model - Naive Bayes with TF-IDF encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1upkQU5sLMrq",
        "outputId": "c537f396-0bc7-4efd-8421-8b8eb14b02bf"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "model_0 = Pipeline([\n",
        "          ('tfidf',TfidfVectorizer()),\n",
        "          ('clf',MultinomialNB())\n",
        "])\n",
        "\n",
        "model_0.fit(x_train,y_train)\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSKh93mpLM0L",
        "outputId": "93a71de0-5efa-4ebe-88b9-5b267305503b"
      },
      "source": [
        "model0_score = model_0.score(x_test,y_test)\n",
        "model0_score"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7926509186351706"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_gwwJsdC13S",
        "outputId": "ee628222-b821-432b-d5a3-0f4403f19239"
      },
      "source": [
        "model0_preds = model_0.predict(x_test)\n",
        "model0_preds[:20]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQRcx6-vC1_V"
      },
      "source": [
        "#Creating a classification metrics function\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true,y_pred):\n",
        "  acc = accuracy_score(y_true,y_pred)*100\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = { \"Accuracy\":acc,\n",
        "                    \"Precision\":model_precision,\n",
        "                    \"Recall\" :model_recall,\n",
        "                     \"F1_score\":model_f1 \n",
        "  }\n",
        "  return model_results\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxuQChVzC2Eh",
        "outputId": "e3ff4538-8e02-45ec-b38a-152fa8142289"
      },
      "source": [
        "calculate_results(y_test,model0_preds)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': 79.26509186351706,\n",
              " 'F1_score': 0.7862189758049549,\n",
              " 'Precision': 0.8111390004213173,\n",
              " 'Recall': 0.7926509186351706}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQ2xJx3CFbUK"
      },
      "source": [
        "# Model_1:Dense NN model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5m-78xpcFhIs"
      },
      "source": [
        "Dense NN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Avzgi9NzC2JI"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape=(1,),dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Dense(10,activation='relu')(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "outputs = layers.Dense(1,activation='sigmoid')(x)\n",
        "\n",
        "model_1 = tf.keras.Model(inputs,outputs)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58EAC3V3Hyb8",
        "outputId": "2b1c10ac-8e9d-4461-aada-a6869fa0c2f9"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization (TextVect (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 15, 10)            1290      \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 1,281,301\n",
            "Trainable params: 1,281,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY7dVWbhC2Md"
      },
      "source": [
        "model_1.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics = ['accuracy'])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muiq2suHHA5f",
        "outputId": "dad78182-5f4c-493b-ad5d-5b85e0774119"
      },
      "source": [
        "history_1  = model_1.fit(x_train,y_train,epochs=10,\n",
        "                         validation_data = (x_test,y_test),\n",
        "                         callbacks=[create_tensorboard_callback(dir_name='training_logs',\n",
        "                                                               experiment_name='model_1_dense')]\n",
        "                        )"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: training_logs/model_1_dense/20210521-154646\n",
            "Epoch 1/10\n",
            "215/215 [==============================] - 7s 19ms/step - loss: 0.6508 - accuracy: 0.6310 - val_loss: 0.4920 - val_accuracy: 0.7769\n",
            "Epoch 2/10\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.4025 - accuracy: 0.8363 - val_loss: 0.4600 - val_accuracy: 0.7874\n",
            "Epoch 3/10\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.2866 - accuracy: 0.8857 - val_loss: 0.4969 - val_accuracy: 0.7953\n",
            "Epoch 4/10\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.2288 - accuracy: 0.9074 - val_loss: 0.4946 - val_accuracy: 0.7835\n",
            "Epoch 5/10\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.1769 - accuracy: 0.9340 - val_loss: 0.5338 - val_accuracy: 0.7900\n",
            "Epoch 6/10\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.1453 - accuracy: 0.9450 - val_loss: 0.5859 - val_accuracy: 0.7822\n",
            "Epoch 7/10\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.1174 - accuracy: 0.9592 - val_loss: 0.6423 - val_accuracy: 0.7848\n",
            "Epoch 8/10\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0984 - accuracy: 0.9628 - val_loss: 0.6864 - val_accuracy: 0.7756\n",
            "Epoch 9/10\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.0882 - accuracy: 0.9693 - val_loss: 0.7381 - val_accuracy: 0.7690\n",
            "Epoch 10/10\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.0798 - accuracy: 0.9724 - val_loss: 0.7826 - val_accuracy: 0.7690\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rU1aDfpMI0EO",
        "outputId": "2ec0a1cb-057e-4bda-8184-ba80e71494fb"
      },
      "source": [
        "model_1_pred = tf.squeeze(tf.round(model_1.predict(x_test)))\n",
        "model_1_pred"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
              "array([1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
              "       1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
              "       0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
              "       0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
              "       0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
              "       0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
              "       1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
              "       1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
              "       0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
              "       0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
              "       0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0.],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yy3vCh9vI9W9",
        "outputId": "3684e699-4fd6-4745-8b12-dea5bf0dcc1e"
      },
      "source": [
        "calculate_results(y_test,model_1_pred)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': 76.9028871391076,\n",
              " 'F1_score': 0.7666669868908192,\n",
              " 'Precision': 0.7711368167182066,\n",
              " 'Recall': 0.7690288713910761}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYU2ar4MPc6v"
      },
      "source": [
        "weights = model_1.get_layer('embedding').get_weights()[0]\n",
        "vocab = text_vectorizer.get_vocabulary()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-z9X1ThAOWl6"
      },
      "source": [
        "# Model_2 :LSTM model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnV3tSAgRbIP"
      },
      "source": [
        "LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBPD3gaPJFjX"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape=(1,),dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.LSTM(16,return_sequences=True,dropout=.5)(x)\n",
        "x = layers.LSTM(16,dropout=.5)(x)\n",
        "x = layers.Dense(10,activation='relu')(x)\n",
        "outputs = layers.Dense(1,activation='sigmoid')(x)\n",
        "\n",
        "model_2 = tf.keras.Model(inputs,outputs)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EmaEVaOTaim",
        "outputId": "a5c9037e-a18a-4dab-f906-8a25b918ebf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_2.summary()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization (TextVect (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 15, 16)            9280      \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 16)                2112      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                170       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 1,291,573\n",
            "Trainable params: 1,291,573\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvLdZl5dRiz0"
      },
      "source": [
        "model_2.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics = ['accuracy'])"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZzztAzGRi-H",
        "outputId": "19ba2041-4cf7-423f-b8ce-af5ffd872163",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history_2  = model_2.fit(x_train,y_train,epochs=5,\n",
        "                         validation_data = (x_test,y_test),\n",
        "                         callbacks=[create_tensorboard_callback(dir_name='training_logs',\n",
        "                                                               experiment_name='model_2_rnn')]\n",
        "                        )"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: training_logs/model_2_rnn/20210521-154722\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 37s 25ms/step - loss: 0.3994 - accuracy: 0.8428 - val_loss: 0.6814 - val_accuracy: 0.7690\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.0896 - accuracy: 0.9701 - val_loss: 0.7670 - val_accuracy: 0.7703\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.0852 - accuracy: 0.9706 - val_loss: 0.7803 - val_accuracy: 0.7651\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.0725 - accuracy: 0.9719 - val_loss: 0.9375 - val_accuracy: 0.7690\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.0627 - accuracy: 0.9764 - val_loss: 1.0292 - val_accuracy: 0.7638\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcKbGnjjVlPj",
        "outputId": "4cd62bad-3a6e-49ab-f360-8a87cc4d9708",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_2_pred = tf.squeeze(tf.round(model_2.predict(x_test)))\n",
        "model_2_pred"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
              "       1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
              "       1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
              "       1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
              "       0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
              "       0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
              "       0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
              "       1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
              "       1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
              "       0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
              "       0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1.,\n",
              "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
              "       0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0.],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-vDv4WTVsRN",
        "outputId": "5c30e1ab-7768-4106-eb1e-b02cf59af8ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "calculate_results(y_test,model_2_pred)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': 76.37795275590551,\n",
              " 'F1_score': 0.761768588939328,\n",
              " 'Precision': 0.7649838845988884,\n",
              " 'Recall': 0.7637795275590551}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jq2ysBwVmoyi"
      },
      "source": [
        "# Model_3 : GRU model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsmZ0KOgmumq"
      },
      "source": [
        "GRU model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSLPgAwSmhoU"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape=(1,),dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.GRU(16)(x)\n",
        "x = layers.Dense(10,activation='relu')(x)\n",
        "outputs = layers.Dense(1,activation='sigmoid')(x)\n",
        "\n",
        "model_3 = tf.keras.Model(inputs,outputs)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqjqbvXymhz3"
      },
      "source": [
        "model_3.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics = ['accuracy'])"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BK1hWhJm-6p",
        "outputId": "c5750dc3-0b38-4c49-86d1-5c8aff1499cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history_3  = model_3.fit(x_train,y_train,epochs=5,\n",
        "                         validation_data = (x_test,y_test),\n",
        "                         callbacks=[create_tensorboard_callback(dir_name='training_logs',\n",
        "                                                               experiment_name='model_3_rnn')]\n",
        "                        )"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: training_logs/model_3_rnn/20210521-155158\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 6s 20ms/step - loss: 0.4695 - accuracy: 0.7602 - val_loss: 0.7325 - val_accuracy: 0.7703\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0749 - accuracy: 0.9720 - val_loss: 0.7838 - val_accuracy: 0.7703\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0627 - accuracy: 0.9767 - val_loss: 0.9111 - val_accuracy: 0.7690\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0482 - accuracy: 0.9783 - val_loss: 0.9245 - val_accuracy: 0.7677\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0428 - accuracy: 0.9825 - val_loss: 0.9994 - val_accuracy: 0.7638\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fO7LOihQnI0k",
        "outputId": "5cfc59c0-d852-4a7d-8b11-11fcefe0a187",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_3.summary()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization (TextVect (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 16)                7008      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                170       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 1,287,189\n",
            "Trainable params: 1,287,189\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCc8AVTBnI8J",
        "outputId": "9616e530-d933-4eac-e6d6-99936f556e7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_3_pred = tf.squeeze(tf.round(model_3.predict(x_test)))\n",
        "model_3_pred"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
              "       1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
              "       1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
              "       0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
              "       1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
              "       0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
              "       0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
              "       0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
              "       1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
              "       0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
              "       0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
              "       0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
              "       1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWjGjIPqnOdE",
        "outputId": "f10b78d4-de4a-43ee-f343-0fd742e51e29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "calculate_results(y_test,model_3_pred)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': 76.37795275590551,\n",
              " 'F1_score': 0.762372083327101,\n",
              " 'Precision': 0.7640630933275061,\n",
              " 'Recall': 0.7637795275590551}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VW9wYKMRsdbD"
      },
      "source": [
        "# Model_4 : Bi-directional LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYDa_tHosf31"
      },
      "source": [
        "Bi-directional LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZDEraHbshQ2"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape=(1,),dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Bidirectional(layers.LSTM(32,dropout=.5,return_sequences=True))(x)\n",
        "x = layers.Bidirectional(layers.LSTM(32,dropout=.5))(x)\n",
        "outputs = layers.Dense(1,activation='sigmoid')(x)\n",
        "\n",
        "model_4 = tf.keras.Model(inputs,outputs)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-2daawXsnlQ"
      },
      "source": [
        "model_4.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=.01),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics = ['accuracy'])"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zrfYjN9snqe",
        "outputId": "531d88d4-74f1-4690-deda-5b3f732f6614",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history_4  = model_4.fit(x_train,y_train,epochs=5,\n",
        "                         validation_data = (x_test,y_test),\n",
        "                         callbacks=[create_tensorboard_callback(dir_name='training_logs',\n",
        "                                                               experiment_name='model_4_rnn')]\n",
        "                        )"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: training_logs/model_4_rnn/20210521-162353\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 12s 31ms/step - loss: 0.2159 - accuracy: 0.9096 - val_loss: 0.7042 - val_accuracy: 0.7638\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 5s 22ms/step - loss: 0.1245 - accuracy: 0.9570 - val_loss: 0.6960 - val_accuracy: 0.7703\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 5s 21ms/step - loss: 0.0921 - accuracy: 0.9667 - val_loss: 0.9279 - val_accuracy: 0.7493\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 21ms/step - loss: 0.0700 - accuracy: 0.9733 - val_loss: 0.9478 - val_accuracy: 0.7467\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.0638 - accuracy: 0.9702 - val_loss: 1.0967 - val_accuracy: 0.7520\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PzIi8n-snuN",
        "outputId": "60a2f8a4-e790-407a-bbca-9d0e27941c8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_4_pred = tf.squeeze(tf.round(model_4.predict(x_test)))\n",
        "model_4_pred[:10]"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 0., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-Mo3o4lsnzm",
        "outputId": "b5472c12-b548-4ab3-8c74-8f078e8f88ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "calculate_results(y_test,model_4_pred)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': 76.24671916010499,\n",
              " 'F1_score': 0.7599672431611975,\n",
              " 'Precision': 0.7645157014219752,\n",
              " 'Recall': 0.7624671916010499}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQLGSUACvg0b"
      },
      "source": [
        "# Model_5 : 1D Conv NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xjc7WWYnvme1"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape=(1,),dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Conv1D(64,3,activation='relu',padding='same')(x)\n",
        "x = layers.Conv1D(64,3,activation='relu',padding='same')(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "outputs = layers.Dense(1,activation='sigmoid')(x)\n",
        "\n",
        "model_5 = tf.keras.Model(inputs,outputs)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1ti5igbwWu7",
        "outputId": "fa3baec1-1522-48da-9477-d831a0b91f68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_5.summary()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_16 (InputLayer)        [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization (TextVect (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "conv1d_11 (Conv1D)           (None, 15, 64)            24640     \n",
            "_________________________________________________________________\n",
            "conv1d_12 (Conv1D)           (None, 15, 64)            12352     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_2 ( (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,317,057\n",
            "Trainable params: 1,317,057\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1Jvu16Fvrgz"
      },
      "source": [
        "model_5.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics = ['accuracy'])"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUeK1HapvrlY",
        "outputId": "693a59e0-211f-4be9-e7e9-67480d97b267",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history_5  = model_5.fit(x_train,y_train,epochs=5,\n",
        "                         validation_data = (x_test,y_test),\n",
        "                         callbacks=[create_tensorboard_callback(dir_name='training_logs',\n",
        "                                                               experiment_name='model_5conv1d')]\n",
        "                        )"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: training_logs/model_5conv1d/20210521-163459\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 18ms/step - loss: 0.1932 - accuracy: 0.9456 - val_loss: 1.2733 - val_accuracy: 0.7651\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.0387 - accuracy: 0.9841 - val_loss: 1.4326 - val_accuracy: 0.7677\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.0389 - accuracy: 0.9829 - val_loss: 1.6888 - val_accuracy: 0.7664\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.0357 - accuracy: 0.9832 - val_loss: 1.6843 - val_accuracy: 0.7585\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.0389 - accuracy: 0.9818 - val_loss: 1.9899 - val_accuracy: 0.7677\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEMAcBSvvrqV",
        "outputId": "1c5cbb5d-0e27-481a-c107-e7f75d6cff85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_5_pred = tf.squeeze(tf.round(model_5.predict(x_test)))\n",
        "model_5_pred[:10]"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTLZ1zMovruO",
        "outputId": "3e7bb2dd-1d99-4648-ab40-f0cfceff6529",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "calculate_results(y_test,model_5_pred)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': 76.77165354330708,\n",
              " 'F1_score': 0.7654097439388935,\n",
              " 'Precision': 0.7696465472028295,\n",
              " 'Recall': 0.7677165354330708}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSHg9ClrzJF8"
      },
      "source": [
        "# Model_6 : Transfer Learning from Tensorflow hub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UVDHYEPvrx0",
        "outputId": "7a6f4757-7d3b-4564-e3ec-e607e0513068",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "embed = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                       input_shape=[], dtype=tf.string,\n",
        "                       trainable=False)\n",
        "\n",
        "model_6 = tf.keras.Sequential([\n",
        "        embed,\n",
        "        layers.Dense(64,activation='relu'),\n",
        "        layers.Dense(1,activation='sigmoid')                       \n",
        "])"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:8 out of the last 8 calls to <function recreate_function.<locals>.restored_function_body at 0x7efe802d0d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:8 out of the last 8 calls to <function recreate_function.<locals>.restored_function_body at 0x7efe802d0d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhWi_gP11lGN",
        "outputId": "eee353b5-031e-44b4-ef12-deb2949cd2e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_6.summary()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer_3 (KerasLayer)   (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLvG01vRzVzC"
      },
      "source": [
        "model_6.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics = ['accuracy'])"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BT-IuygzV2g",
        "outputId": "3237da90-73bf-4150-a98b-533b45976a17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history_6  = model_6.fit(x_train,y_train,epochs=10,\n",
        "                         validation_data = (x_test,y_test),\n",
        "                         callbacks=[create_tensorboard_callback(dir_name='training_logs',\n",
        "                                                               experiment_name='model_6trans')]\n",
        "                        )"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: training_logs/model_6trans/20210521-170242\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function CapturableResourceDeleter.__del__ at 0x7effb4a22680>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/tracking.py\", line 208, in __del__\n",
            "    self._destroy_resource()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 828, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 871, in _call\n",
            "    self._initialize(args, kwds, add_initializers_to=initializers)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 726, in _initialize\n",
            "    *args, **kwds))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 2969, in _get_concrete_function_internal_garbage_collected\n",
            "    graph_function, _ = self._maybe_define_function(args, kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 3361, in _maybe_define_function\n",
            "    graph_function = self._create_graph_function(args, kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 3206, in _create_graph_function\n",
            "    capture_by_value=self._capture_by_value),\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 990, in func_graph_from_py_func\n",
            "    func_outputs = python_func(*func_args, **func_kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 634, in wrapped_fn\n",
            "    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/function_deserialization.py\", line 253, in restored_function_body\n",
            "    return _call_concrete_function(function, inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/function_deserialization.py\", line 75, in _call_concrete_function\n",
            "    result = function._call_flat(tensor_inputs, function._captured_inputs)  # pylint: disable=protected-access\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/load.py\", line 116, in _call_flat\n",
            "    cancellation_manager)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 1932, in _call_flat\n",
            "    flat_outputs = forward_function.call(ctx, args_with_tangents)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 589, in call\n",
            "    executor_type=executor_type)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/functional_ops.py\", line 1206, in partitioned_call\n",
            "    f.add_to_graph(graph)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 505, in add_to_graph\n",
            "    g._add_function(self)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 3396, in _add_function\n",
            "    gradient)\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError: 'func' argument to TF_GraphCopyFunction cannot be null\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:9 out of the last 9 calls to <function recreate_function.<locals>.restored_function_body at 0x7eff46eb87a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:9 out of the last 9 calls to <function recreate_function.<locals>.restored_function_body at 0x7eff46eb87a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "215/215 [==============================] - 7s 19ms/step - loss: 0.5798 - accuracy: 0.7455 - val_loss: 0.4448 - val_accuracy: 0.7979\n",
            "Epoch 2/10\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.4179 - accuracy: 0.8149 - val_loss: 0.4372 - val_accuracy: 0.8110\n",
            "Epoch 3/10\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.4091 - accuracy: 0.8144 - val_loss: 0.4338 - val_accuracy: 0.8084\n",
            "Epoch 4/10\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.3935 - accuracy: 0.8266 - val_loss: 0.4278 - val_accuracy: 0.8110\n",
            "Epoch 5/10\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.3848 - accuracy: 0.8339 - val_loss: 0.4281 - val_accuracy: 0.8136\n",
            "Epoch 6/10\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.3790 - accuracy: 0.8328 - val_loss: 0.4223 - val_accuracy: 0.8176\n",
            "Epoch 7/10\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.3772 - accuracy: 0.8323 - val_loss: 0.4275 - val_accuracy: 0.8215\n",
            "Epoch 8/10\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.3667 - accuracy: 0.8345 - val_loss: 0.4246 - val_accuracy: 0.8136\n",
            "Epoch 9/10\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.3467 - accuracy: 0.8506 - val_loss: 0.4284 - val_accuracy: 0.8189\n",
            "Epoch 10/10\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.3320 - accuracy: 0.8560 - val_loss: 0.4350 - val_accuracy: 0.8163\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ql6iP0TZzV6e",
        "outputId": "232698fc-008d-47a2-991d-32780bf1b2ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_6_pred = tf.squeeze(tf.round(model_6.predict(x_test)))\n",
        "model_6_pred[:10]"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr1swmEczV-N",
        "outputId": "b0f7d44d-748d-420e-a064-0d6742147bb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "calculate_results(y_test,model_6_pred)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': 81.62729658792651,\n",
              " 'F1_score': 0.813022410660206,\n",
              " 'Precision': 0.8252416515568405,\n",
              " 'Recall': 0.8162729658792651}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    }
  ]
}